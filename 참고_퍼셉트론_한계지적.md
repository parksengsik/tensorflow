## 퍼셉트론의 한계지적
### 소개
* 뉴런의 원조격인 퍼셉트론의 한계 지적에서 쓰인 AND, OR, XOR 연산을 할 수 있는 신경망 네트워크를 만들어봅시다.
### 퍼셉트론의 한계 지적에서 쓰인 AND,OR,XOR 연산 신경망 네트워크 
#### 1. 라이브러리와 함수 선언하기. 
```python
import tensorflow as tf
import numpy as np
import math

# 시그모이드 함수
def sigmoid(x):
    return 1 / (1 + math.exp(-x))
```

#### 2. 첫 번째 신경망 네트워크 AND를 만들어보자. 
```python
# 첫 번째 신경망 네트워크 : AND
x = np.array([[1,1],[1,0],[0,1],[0,0]])
y = np.array([[1], [0], [0], [0]])
w = tf.random.normal([2],0,1)
b = tf.random.normal([1],0,1)
b_x = 1

for i in range(0,2000) :
    error_sum = 0
    for j in range(4) :
        output = sigmoid(np.sum(x[j]*w)+b_x*b)
        error = y[j][0] - output
        w = w + x[j] * 0.1 * error
        b = b + b_x * 0.1 * error
        error_sum += error
    if i % 200 == 99 :
        print(i, error_sum)
        
# 출력
>> 99 -0.16087775134773874
299 -0.08033600003478689
499 -0.05371569062794952
699 -0.040213792818322526
899 -0.03206287113584773
1099 -0.026622329787033702
1299 -0.022738829488517135
1499 -0.019832152784422918
1699 -0.01757735643714221
1899 -0.015777930891931594
```
```python
# AND 네트워크 평가
for i in range(4):
    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))
    
# 출력
>> X: [1 1] Y: [1] Output: 0.964966100605754
X: [1 0] Y: [0] Output: 0.02482694744439901
X: [0 1] Y: [0] Output: 0.024902606770609598
X: [0 0] Y: [0] Output: 2.3605033365351133e-05
```

#### 3. 두 번째 신경망 네트워크 OR을 만들어보자. 
```python
# 두 번째 신경망 네트워크 : OR
x = np.array([[1,1],[1,0],[0,1],[0,0]])
y = np.array([[1],[1],[1],[0]])
w = tf.random.normal([2],0,1)
b = tf.random.normal([1],0,1)
b_x = 1

for i in range(2000):
    error_sum = 0
    for j in range(4):
        output = sigmoid(np.sum(x[j]*w)+b_x*b)
        error = y[j][0] - output
        w = w + x[j] * 0.1 * error
        b = b + b_x * 0.1 * error
        error_sum += error

    if i % 200 == 99:
        print(i,error_sum)
        
# 출력
>> 99 -0.09950230740597865
299 -0.03535990538173148
499 -0.021324927348043338
699 -0.015184427703754777
899 -0.011758584064853056
1099 -0.00958036498602921
1299 -0.008076285047359903
1499 -0.006976768156483848
1699 -0.006138217367316921
1899 -0.005478279915358444
```
```python
# OR 네트워크 평가
for i in range(4):
    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))
    
# 출력
>> X: [1 1] Y: [1] Output: 0.9999971256818193
X: [1 0] Y: [1] Output: 0.9896936211856563
X: [0 1] Y: [1] Output: 0.9896728222316397
X: [0 0] Y: [0] Output: 0.025769302574021546
```

#### 4. 세 번째 신경망 네트워크 XOR을 만들어보자. 
```python
# 세 번째 신경망 네트워크 : XOR
x = np.array([[1,1], [1,0], [0,1], [0,0]])
y = np.array([[0], [1], [1], [0]])
w = tf.random.normal([2],0,1)
b = tf.random.normal([1],0,1)
b_x = 1

for i in range(2000) :
    error_sum = 0
    for j in range(4):
        output = sigmoid(np.sum(x[j]*w)+b_x*b)
        error = y[j][0] - output
        w = w + x[j] * 0.1 * error
        b = b + b_x *0.1 * error
        error_sum += error
    
    if i % 200 == 199:
        print(i,error_sum)
        
# 출력
>> 199 -0.00044523298959109336
399 -1.8105052288719392e-05
599 -7.464297520076713e-07
799 -8.376394911024931e-09
999 3.722842145670313e-09
1199 3.722842145670313e-09
1399 3.722842145670313e-09
1599 3.722842145670313e-09
1799 3.722842145670313e-09
1999 3.722842145670313e-09
```
```python
# XOR 네트워크 평가
for i in range(4):
    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))
    
# 출력
>> X: [1 1] Y: [0] Output: 0.5128176286712095
X: [1 0] Y: [1] Output: 0.5128176305326305
X: [0 1] Y: [1] Output: 0.4999999990686774
X: [0 0] Y: [0] Output: 0.5000000009313226
```

#### 5. 신경망 네트워크 XOR을 tf.keras를 이용하여 만들어보자
```python
# tf.keras를 이용한 XOR 네트워크 연산
x = np.array([[1,1], [1,0], [0,1], [0,0]])
y = np.array([[0],[1],[1],[0]])

model = tf.keras.Sequential([
                             tf.keras.layers.Dense(units=2, activation='sigmoid', input_shape=(2,)),
                             tf.keras.layers.Dense(units=1, activation='sigmoid')
])

model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.1), loss = 'mse')

model.summary()

# 출력
>> Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 2)                 6         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 3         
=================================================================
Total params: 9
Trainable params: 9
Non-trainable params: 0
_________________________________________________________________
```
```python
# tf.keras를 이용한 2-레이어 XOR 네트워크 학습
history = model.fit(x, y, epochs=2000, batch_size=1)

# 출력
>> ...
Epoch 1992/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0932
Epoch 1993/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0929
Epoch 1994/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0927
Epoch 1995/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0924
Epoch 1996/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0922
Epoch 1997/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0920
Epoch 1998/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0917
Epoch 1999/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0915
Epoch 2000/2000
4/4 [==============================] - 0s 1ms/step - loss: 0.0913
```
```python
# tf.keras를 이용한 2-레이어 XOR 네트워크 평가
model.predict(x)

# 출력
>> array([[0.24899915],
       [0.74529886],
       [0.6281929 ],
       [0.3015707 ]], dtype=float32)
```
